{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Economic Resilience Predictor \n",
    "\n",
    "## Capstone Project Phase 1b: World Bank Data Collection\n",
    "This notebook handles the data collection phase for the economic shock resilience project. The Collection Phase is divided in two steps: Madisson Focused Collection (1a)\n",
    "and World Bank Collection implemented in the present notebook\n",
    "\n",
    "\n",
    "**Objectives:**\n",
    "- Collect 25+ World Bank indicators for our proven country set\n",
    "- Focus on the same 38 countries that worked perfectly with Maddison\n",
    "- Target period: 1990-2023\n",
    "- Enhanced economic, financial and institutional indicators\n",
    "- Maintain high data quality standards\n",
    "- Integrate datasets for comprehensive analysis\n",
    "- Calculate initial resilience metrics\n",
    "- Prepare data for EDA phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORLD BANK DATA COLLECTION - Phase 1B\n",
      "=======================================================\n",
      "Target countries: 38\n",
      "Target indicators: 26\n",
      "Time period: 1990-2023\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# World Bank Data Collection - Phase 1B\n",
    "# ====================================================\n",
    "# Building on Maddison Success, we will collect more data to complete information for our 38 countries, World Bank Indicator will enrich our analysis providing more sources \n",
    "# to calculate and measure economic resilience\n",
    " \n",
    "# Environment Setup\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 15)\n",
    "\n",
    "# Load configuration\n",
    "sys.path.append(\"config\")\n",
    "from data_collection_config import *\n",
    "\n",
    "print(\"WORLD BANK DATA COLLECTION - Phase 1B\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"Target countries: {len(FOCUS_COUNTRIES)}\")\n",
    "print(f\"Target indicators: {len(WORLD_BANK_INDICATORS)}\")\n",
    "print(f\"Time period: {START_YEAR}-{END_YEAR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MADDISON SUCCESS RESULTS\n",
      "========================================\n",
      "Maddison data loaded: (1254, 6)\n",
      "High-quality countries: 38\n",
      "Countries: ARG, AUS, AUT, BEL, BRA, CAN, CHE, CHL, CHN, COL, CZE, DEU, DNK, ESP, FIN, FRA, GBR, HUN, IDN, IND, IRL, ITA, JPN, KOR, MEX, MYS, NLD, NOR, NZL, PHL, POL, PRT, RUS, SWE, THA, TUR, USA, ZAF\n",
      "\n",
      " COVERAGE VERIFICATION:\n",
      "   Expected: 38 countries\n",
      "   Found: 38 high-quality\n",
      "   Success rate: 100.0%\n",
      "Ready to proceed with World Bank collection!\n"
     ]
    }
   ],
   "source": [
    "# Load our Maddison data and country recommendations\n",
    "# ===========================================================\n",
    "\n",
    "print(\"LOADING MADDISON SUCCESS RESULTS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    # Load the successful Maddison data\n",
    "    maddison_data = pd.read_csv('data/maddison_focused_test.csv')\n",
    "    print(f\"Maddison data loaded: {maddison_data.shape}\")\n",
    "    \n",
    "    # Load country recommendations\n",
    "    with open('data/country_recommendations.json', 'r') as f:\n",
    "        recommendations = json.load(f)\n",
    "    \n",
    "    high_quality_countries = recommendations['high_quality_countries']\n",
    "    print(f\"High-quality countries: {len(high_quality_countries)}\")\n",
    "    print(f\"Countries: {', '.join(sorted(high_quality_countries))}\")\n",
    "    \n",
    "    # Verify we have all expected countries\n",
    "    print(f\"\\n COVERAGE VERIFICATION:\")\n",
    "    print(f\"   Expected: {len(FOCUS_COUNTRIES)} countries\")\n",
    "    print(f\"   Found: {len(high_quality_countries)} high-quality\")\n",
    "    print(f\"   Success rate: {len(high_quality_countries)/len(FOCUS_COUNTRIES):.1%}\")\n",
    "    \n",
    "    success_base = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  Error loading previous results: {e}\")\n",
    "    print(\"   Please ensure test_focused_collection.ipynb completed successfully\")\n",
    "    success_base = False\n",
    "\n",
    "if success_base:\n",
    "    print(f\"Ready to proceed with World Bank collection!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SETTING UP WORLD BANK COLLECTION FUNCTIONS\n",
      "==================================================\n",
      "Collection functions ready\n"
     ]
    }
   ],
   "source": [
    "# Define functions for World Bank data collection \n",
    "# ===========================================================\n",
    "\n",
    "print(\"SETTING UP WORLD BANK COLLECTION FUNCTIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def collect_wb_indicator_with_progress(indicator_code: str, indicator_name: str, \n",
    "                                     target_countries: List[str]) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Collect a single World Bank indicator with detailed progress reporting.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    indicator_code : str\n",
    "        World Bank API indicator code\n",
    "    indicator_name : str  \n",
    "        Human-readable indicator name\n",
    "    target_countries : List[str]\n",
    "        List of target country codes\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Optional[pd.DataFrame] : Collected data or None if failed\n",
    "    \"\"\"\n",
    "    \n",
    "    max_retries = 3\n",
    "    retry_delay = 2\n",
    "    \n",
    "    print(f\"Collecting: {indicator_name}\")\n",
    "    \n",
    "    for retry in range(max_retries):\n",
    "        try:\n",
    "            # Construct API request\n",
    "            url = f\"https://api.worldbank.org/v2/country/all/indicator/{indicator_code}\"\n",
    "            params = {\n",
    "                'format': 'json',\n",
    "                'date': f'{START_YEAR}:{END_YEAR}',\n",
    "                'per_page': 15000,  # Generous page size\n",
    "                'page': 1\n",
    "            }\n",
    "            \n",
    "            # Make request with timeout\n",
    "            response = requests.get(url, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Parse response\n",
    "            data = response.json()\n",
    "            \n",
    "            if not isinstance(data, list) or len(data) < 2:\n",
    "                print(f\"      Invalid response structure\")\n",
    "                if retry < max_retries - 1:\n",
    "                    time.sleep(retry_delay)\n",
    "                continue\n",
    "            \n",
    "            # Extract records\n",
    "            records_data = data[1]\n",
    "            if not records_data:\n",
    "                print(f\"      No data returned\")\n",
    "                if retry < max_retries - 1:\n",
    "                    time.sleep(retry_delay)\n",
    "                continue\n",
    "            \n",
    "            # Process records\n",
    "            valid_records = []\n",
    "            \n",
    "            for item in records_data:\n",
    "                if not isinstance(item, dict):\n",
    "                    continue\n",
    "                \n",
    "                # Extract data\n",
    "                country_info = item.get('country', {})\n",
    "                country_code = country_info.get('id')\n",
    "                country_name = country_info.get('value')\n",
    "                year_str = item.get('date')\n",
    "                value = item.get('value')\n",
    "                \n",
    "                # Validate record\n",
    "                if (country_code and year_str and value is not None and \n",
    "                    country_code in target_countries):\n",
    "                    \n",
    "                    try:\n",
    "                        year = int(year_str)\n",
    "                        value_float = float(value)\n",
    "                        \n",
    "                        valid_records.append({\n",
    "                            'country_code': country_code,\n",
    "                            'country_name': country_name,\n",
    "                            'year': year,\n",
    "                            'indicator_code': indicator_code,\n",
    "                            'indicator_name': indicator_name,\n",
    "                            'value': value_float\n",
    "                        })\n",
    "                    except (ValueError, TypeError):\n",
    "                        continue\n",
    "            \n",
    "            if valid_records:\n",
    "                df = pd.DataFrame(valid_records)\n",
    "                countries_found = df['country_code'].nunique()\n",
    "                year_range = f\"{df['year'].min()}-{df['year'].max()}\"\n",
    "                \n",
    "                print(f\"      Success: {len(valid_records)} records, {countries_found} countries, {year_range}\")\n",
    "                return df\n",
    "            else:\n",
    "                print(f\"      ⚠️ No valid records found\")\n",
    "                if retry < max_retries - 1:\n",
    "                    time.sleep(retry_delay)\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"      Request error (attempt {retry + 1}): {str(e)[:100]}\")\n",
    "            if retry < max_retries - 1:\n",
    "                time.sleep(retry_delay * (retry + 1))\n",
    "        except Exception as e:\n",
    "            print(f\"      Processing error (attempt {retry + 1}): {str(e)[:100]}\")\n",
    "            if retry < max_retries - 1:\n",
    "                time.sleep(retry_delay)\n",
    "    \n",
    "    print(f\"Failed after {max_retries} attempts\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def assess_indicator_quality(df: pd.DataFrame, target_countries: List[str]) -> Dict:\n",
    "    \"\"\"Assess the quality of collected indicator data.\"\"\"\n",
    "    \n",
    "    if df is None or df.empty:\n",
    "        return {'quality_score': 0, 'countries_covered': 0, 'completeness': 0}\n",
    "    \n",
    "    countries_covered = df['country_code'].nunique()\n",
    "    country_coverage = countries_covered / len(target_countries)\n",
    "    \n",
    "    # Calculate completeness by country\n",
    "    country_completeness = df.groupby('country_code')['value'].apply(\n",
    "        lambda x: x.notna().mean()\n",
    "    ).mean()\n",
    "    \n",
    "    # Overall quality score\n",
    "    quality_score = 0.6 * country_coverage + 0.4 * country_completeness\n",
    "    \n",
    "    return {\n",
    "        'quality_score': quality_score,\n",
    "        'countries_covered': countries_covered,\n",
    "        'country_coverage': country_coverage,\n",
    "        'completeness': country_completeness,\n",
    "        'total_records': len(df)\n",
    "    }\n",
    "\n",
    "print(\"Collection functions ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUGGING WORLD BANK API COLLECTION\n",
      "==================================================\n",
      "Starting API debug with known good countries...\n",
      "Testing indicator: NY.GDP.PCAP.KD\n",
      "Sample countries: ['USA', 'GBR', 'DEU', 'FRA', 'JPN']\n",
      "API URL: https://api.worldbank.org/v2/country/all/indicator/NY.GDP.PCAP.KD\n",
      "Parameters: {'format': 'json', 'date': '1990:2023', 'per_page': 1000, 'page': 1}\n",
      "Response status: 200\n",
      "Response type: <class 'list'>\n",
      "Response length: 2\n",
      "\n",
      "PAGINATION INFO:\n",
      "   Total records: 9044\n",
      "   Pages: 10\n",
      "   Per page: 1000\n",
      "\n",
      "RECORDS DATA:\n",
      "   Records type: <class 'list'>\n",
      "   Records count: 1000\n",
      "\n",
      "SAMPLE RECORD STRUCTURE:\n",
      "   Record type: <class 'dict'>\n",
      "   Keys: ['indicator', 'country', 'countryiso3code', 'date', 'value', 'unit', 'obs_status', 'decimal']\n",
      "   Country info: {'id': 'ZH', 'value': 'Africa Eastern and Southern'}\n",
      "   Date: 2023\n",
      "   Value: 1418.3637366532\n",
      "\n",
      "MATCHING ANALYSIS (first 100 records):\n",
      "   Records matching target countries: 0\n",
      "   Unique countries found: 3\n",
      "   Sample countries found: set()\n",
      "   All countries sample: ['1A', 'ZH', 'ZI']\n",
      "\n",
      "Debug successful - got sample data\n",
      "Sample records:\n",
      "Record 1: {'indicator': {'id': 'NY.GDP.PCAP.KD', 'value': 'GDP per capita (constant 2015 US$)'}, 'country': {'id': 'ZH', 'value': 'Africa Eastern and Southern'}, 'countryiso3code': 'AFE', 'date': '2023', 'value': 1418.3637366532, 'unit': '', 'obs_status': '', 'decimal': 1}\n",
      "Record 2: {'indicator': {'id': 'NY.GDP.PCAP.KD', 'value': 'GDP per capita (constant 2015 US$)'}, 'country': {'id': 'ZH', 'value': 'Africa Eastern and Southern'}, 'countryiso3code': 'AFE', 'date': '2022', 'value': 1421.58972754715, 'unit': '', 'obs_status': '', 'decimal': 1}\n",
      "Record 3: {'indicator': {'id': 'NY.GDP.PCAP.KD', 'value': 'GDP per capita (constant 2015 US$)'}, 'country': {'id': 'ZH', 'value': 'Africa Eastern and Southern'}, 'countryiso3code': 'AFE', 'date': '2021', 'value': 1408.86083752216, 'unit': '', 'obs_status': '', 'decimal': 1}\n"
     ]
    }
   ],
   "source": [
    "# DEBUG: Investigate World Bank API Response\n",
    "\n",
    "print(\"DEBUGGING WORLD BANK API COLLECTION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def debug_wb_api_call(indicator_code: str, sample_countries: List[str] = None):\n",
    "    \"\"\"Debug the World Bank API call to understand the issue.\"\"\"\n",
    "    \n",
    "    if sample_countries is None:\n",
    "        sample_countries = ['USA', 'GBR', 'DEU']  # Simple test countries\n",
    "    \n",
    "    print(f\"Testing indicator: {indicator_code}\")\n",
    "    print(f\"Sample countries: {sample_countries}\")\n",
    "    \n",
    "    try:\n",
    "        # Construct URL\n",
    "        url = f\"https://api.worldbank.org/v2/country/all/indicator/{indicator_code}\"\n",
    "        params = {\n",
    "            'format': 'json',\n",
    "            'date': f'{START_YEAR}:{END_YEAR}',\n",
    "            'per_page': 1000,  # Smaller for debugging\n",
    "            'page': 1\n",
    "        }\n",
    "        \n",
    "        print(f\"API URL: {url}\")\n",
    "        print(f\"Parameters: {params}\")\n",
    "        \n",
    "        # Make request\n",
    "        response = requests.get(url, params=params, timeout=30)\n",
    "        print(f\"Response status: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"HTTP Error: {response.status_code}\")\n",
    "            print(f\"Response text: {response.text[:500]}\")\n",
    "            return None\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = response.json()\n",
    "        print(f\"Response type: {type(data)}\")\n",
    "        print(f\"Response length: {len(data) if isinstance(data, list) else 'N/A'}\")\n",
    "        \n",
    "        if isinstance(data, list) and len(data) >= 2:\n",
    "            pagination_info = data[0]\n",
    "            records_data = data[1]\n",
    "            \n",
    "            print(f\"\\nPAGINATION INFO:\")\n",
    "            print(f\"   Total records: {pagination_info.get('total', 'N/A')}\")\n",
    "            print(f\"   Pages: {pagination_info.get('pages', 'N/A')}\")\n",
    "            print(f\"   Per page: {pagination_info.get('per_page', 'N/A')}\")\n",
    "            \n",
    "            print(f\"\\nRECORDS DATA:\")\n",
    "            print(f\"   Records type: {type(records_data)}\")\n",
    "            print(f\"   Records count: {len(records_data) if records_data else 0}\")\n",
    "            \n",
    "            if records_data and len(records_data) > 0:\n",
    "                # Show first few records structure\n",
    "                print(f\"\\nSAMPLE RECORD STRUCTURE:\")\n",
    "                sample_record = records_data[0]\n",
    "                print(f\"   Record type: {type(sample_record)}\")\n",
    "                if isinstance(sample_record, dict):\n",
    "                    print(f\"   Keys: {list(sample_record.keys())}\")\n",
    "                    \n",
    "                    # Show country structure\n",
    "                    country_info = sample_record.get('country', {})\n",
    "                    print(f\"   Country info: {country_info}\")\n",
    "                    \n",
    "                    # Show other fields\n",
    "                    print(f\"   Date: {sample_record.get('date')}\")\n",
    "                    print(f\"   Value: {sample_record.get('value')}\")\n",
    "                \n",
    "                # Check how many records match our criteria\n",
    "                matching_records = 0\n",
    "                countries_found = set()\n",
    "                \n",
    "                for item in records_data[:100]:  # Check first 100\n",
    "                    if isinstance(item, dict):\n",
    "                        country_info = item.get('country', {})\n",
    "                        country_code = country_info.get('id')\n",
    "                        value = item.get('value')\n",
    "                        \n",
    "                        if country_code:\n",
    "                            countries_found.add(country_code)\n",
    "                            \n",
    "                        if country_code in sample_countries and value is not None:\n",
    "                            matching_records += 1\n",
    "                \n",
    "                print(f\"\\nMATCHING ANALYSIS (first 100 records):\")\n",
    "                print(f\"   Records matching target countries: {matching_records}\")\n",
    "                print(f\"   Unique countries found: {len(countries_found)}\")\n",
    "                print(f\"   Sample countries found: {countries_found & set(sample_countries)}\")\n",
    "                print(f\"   All countries sample: {sorted(list(countries_found))[:10]}\")\n",
    "                \n",
    "                return records_data[:10]  # Return sample for further inspection\n",
    "            else:\n",
    "                print(f\"   No records in response\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Unexpected response structure\")\n",
    "            print(f\"Raw response: {str(data)[:500]}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during debugging: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Run the debug\n",
    "if success_base:\n",
    "    print(\"Starting API debug with known good countries...\")\n",
    "    sample_data = debug_wb_api_call('NY.GDP.PCAP.KD', ['USA', 'GBR', 'DEU', 'FRA', 'JPN'])\n",
    "    \n",
    "    if sample_data:\n",
    "        print(f\"\\nDebug successful - got sample data\")\n",
    "        print(\"Sample records:\")\n",
    "        for i, record in enumerate(sample_data[:3]):\n",
    "            print(f\"Record {i+1}: {record}\")\n",
    "    else:\n",
    "        print(f\"\\nDebug failed - no data returned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " FIXED COLLECTION FUNCTION WITH PAGINATION\n",
      "==================================================\n",
      "\n",
      " Testing fixed collection function...\n",
      "   Collecting: gdp_per_capita_constant\n",
      "Total records: 9044, Pages: 10\n",
      "Fetching page 1/10 (0 valid records)\n",
      "Fetching page 2/10 (34 valid records)\n",
      "Fetching page 3/10 (170 valid records)\n",
      "Fetching page 4/10 (226 valid records)\n",
      "Fetching page 5/10 (218 valid records)\n",
      "Fetching page 6/10 (116 valid records)\n",
      "Fetching page 7/10 (184 valid records)\n",
      "Fetching page 8/10 (140 valid records)\n",
      "Fetching page 9/10 (204 valid records)\n",
      "Fetching page 10/10 (0 valid records)\n",
      "      Success: 1292 records, 38 countries, 1990-2023\n",
      "\n",
      " FIXED APPROACH WORKS!\n",
      "   Total records: 1292\n",
      "   Countries found: 38\n",
      "   Year range: 1990-2023\n",
      "\n",
      " COUNTRY COVERAGE:\n",
      "   Found: 38/38 (100.0%)\n",
      "   Countries found: ['ARG', 'AUS', 'AUT', 'BEL', 'BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'HUN', 'IDN', 'IND', 'IRL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD', 'NOR', 'NZL', 'PHL', 'POL', 'PRT', 'RUS', 'SWE', 'THA', 'TUR', 'USA', 'ZAF']\n",
      "\n",
      " SAMPLE DATA:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "      <th>year</th>\n",
       "      <th>indicator_code</th>\n",
       "      <th>indicator_name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2023</td>\n",
       "      <td>NY.GDP.PCAP.KD</td>\n",
       "      <td>gdp_per_capita_constant</td>\n",
       "      <td>12933.249734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2022</td>\n",
       "      <td>NY.GDP.PCAP.KD</td>\n",
       "      <td>gdp_per_capita_constant</td>\n",
       "      <td>13182.793395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2021</td>\n",
       "      <td>NY.GDP.PCAP.KD</td>\n",
       "      <td>gdp_per_capita_constant</td>\n",
       "      <td>12549.281170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2020</td>\n",
       "      <td>NY.GDP.PCAP.KD</td>\n",
       "      <td>gdp_per_capita_constant</td>\n",
       "      <td>11393.050596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2019</td>\n",
       "      <td>NY.GDP.PCAP.KD</td>\n",
       "      <td>gdp_per_capita_constant</td>\n",
       "      <td>12706.397811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2018</td>\n",
       "      <td>NY.GDP.PCAP.KD</td>\n",
       "      <td>gdp_per_capita_constant</td>\n",
       "      <td>13058.328545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2017</td>\n",
       "      <td>NY.GDP.PCAP.KD</td>\n",
       "      <td>gdp_per_capita_constant</td>\n",
       "      <td>13520.112985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2016</td>\n",
       "      <td>NY.GDP.PCAP.KD</td>\n",
       "      <td>gdp_per_capita_constant</td>\n",
       "      <td>13265.886064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2015</td>\n",
       "      <td>NY.GDP.PCAP.KD</td>\n",
       "      <td>gdp_per_capita_constant</td>\n",
       "      <td>13679.626498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2014</td>\n",
       "      <td>NY.GDP.PCAP.KD</td>\n",
       "      <td>gdp_per_capita_constant</td>\n",
       "      <td>13456.131916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_code country_name  year  indicator_code           indicator_name  \\\n",
       "0          ARG    Argentina  2023  NY.GDP.PCAP.KD  gdp_per_capita_constant   \n",
       "1          ARG    Argentina  2022  NY.GDP.PCAP.KD  gdp_per_capita_constant   \n",
       "2          ARG    Argentina  2021  NY.GDP.PCAP.KD  gdp_per_capita_constant   \n",
       "3          ARG    Argentina  2020  NY.GDP.PCAP.KD  gdp_per_capita_constant   \n",
       "4          ARG    Argentina  2019  NY.GDP.PCAP.KD  gdp_per_capita_constant   \n",
       "5          ARG    Argentina  2018  NY.GDP.PCAP.KD  gdp_per_capita_constant   \n",
       "6          ARG    Argentina  2017  NY.GDP.PCAP.KD  gdp_per_capita_constant   \n",
       "7          ARG    Argentina  2016  NY.GDP.PCAP.KD  gdp_per_capita_constant   \n",
       "8          ARG    Argentina  2015  NY.GDP.PCAP.KD  gdp_per_capita_constant   \n",
       "9          ARG    Argentina  2014  NY.GDP.PCAP.KD  gdp_per_capita_constant   \n",
       "\n",
       "          value  \n",
       "0  12933.249734  \n",
       "1  13182.793395  \n",
       "2  12549.281170  \n",
       "3  11393.050596  \n",
       "4  12706.397811  \n",
       "5  13058.328545  \n",
       "6  13520.112985  \n",
       "7  13265.886064  \n",
       "8  13679.626498  \n",
       "9  13456.131916  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DATA POINTS PER COUNTRY (top 10):\n",
      "{'ARG': 34, 'NZL': 34, 'ITA': 34, 'JPN': 34, 'KOR': 34, 'MEX': 34, 'MYS': 34, 'NLD': 34, 'NOR': 34, 'PHL': 34}\n"
     ]
    }
   ],
   "source": [
    "# Fixed World Bank Data Collection with pagination\n",
    "# ==========================================================\n",
    "\n",
    "print(\" FIXED COLLECTION FUNCTION WITH PAGINATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def collect_wb_indicator_fixed(indicator_code: str, indicator_name: str, \n",
    "                             target_countries: List[str]) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Fixed World Bank collection that handles pagination properly.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"   Collecting: {indicator_name}\")\n",
    "    \n",
    "    all_records = []\n",
    "    max_pages = 15  # Safety limit\n",
    "    \n",
    "    try:\n",
    "        # First, get pagination info\n",
    "        url = f\"https://api.worldbank.org/v2/country/all/indicator/{indicator_code}\"\n",
    "        params = {\n",
    "            'format': 'json',\n",
    "            'date': f'{START_YEAR}:{END_YEAR}',\n",
    "            'per_page': 1000,\n",
    "            'page': 1\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if not isinstance(data, list) or len(data) < 2:\n",
    "            print(f\"      ⚠️ Invalid response structure\")\n",
    "            return None\n",
    "        \n",
    "        pagination_info = data[0]\n",
    "        total_pages = pagination_info.get('pages', 1)\n",
    "        total_records = pagination_info.get('total', 0)\n",
    "        \n",
    "        print(f\"Total records: {total_records}, Pages: {total_pages}\")\n",
    "        \n",
    "        # Collect from all pages (up to max_pages for safety)\n",
    "        pages_to_fetch = min(total_pages, max_pages)\n",
    "        \n",
    "        for page in range(1, pages_to_fetch + 1):\n",
    "            print(f\"Fetching page {page}/{pages_to_fetch}\", end=\"\")\n",
    "            \n",
    "            params['page'] = page\n",
    "            response = requests.get(url, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            page_data = response.json()\n",
    "            if isinstance(page_data, list) and len(page_data) >= 2:\n",
    "                records_data = page_data[1]\n",
    "                \n",
    "                if records_data:\n",
    "                    # Process records from this page\n",
    "                    page_valid = 0\n",
    "                    for item in records_data:\n",
    "                        if not isinstance(item, dict):\n",
    "                            continue\n",
    "                        \n",
    "                        # Use countryiso3code field (more reliable)\n",
    "                        country_code = item.get('countryiso3code')\n",
    "                        country_info = item.get('country', {})\n",
    "                        country_name = country_info.get('value')\n",
    "                        year_str = item.get('date')\n",
    "                        value = item.get('value')\n",
    "                        \n",
    "                        # Check if this is one of our target countries\n",
    "                        if (country_code and country_code in target_countries and \n",
    "                            year_str and value is not None):\n",
    "                            \n",
    "                            try:\n",
    "                                year = int(year_str)\n",
    "                                value_float = float(value)\n",
    "                                \n",
    "                                all_records.append({\n",
    "                                    'country_code': country_code,\n",
    "                                    'country_name': country_name,\n",
    "                                    'year': year,\n",
    "                                    'indicator_code': indicator_code,\n",
    "                                    'indicator_name': indicator_name,\n",
    "                                    'value': value_float\n",
    "                                })\n",
    "                                page_valid += 1\n",
    "                                \n",
    "                            except (ValueError, TypeError):\n",
    "                                continue\n",
    "                    \n",
    "                    print(f\" ({page_valid} valid records)\")\n",
    "                else:\n",
    "                    print(f\" (no records)\")\n",
    "            \n",
    "            # Small delay between pages\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        if all_records:\n",
    "            df = pd.DataFrame(all_records)\n",
    "            countries_found = df['country_code'].nunique()\n",
    "            year_range = f\"{df['year'].min()}-{df['year'].max()}\"\n",
    "            \n",
    "            print(f\"      Success: {len(all_records)} records, {countries_found} countries, {year_range}\")\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"      No valid records found across all pages\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\" Error: {str(e)[:100]}\")\n",
    "        return None\n",
    "\n",
    "# Test the fixed function\n",
    "if success_base:\n",
    "    print(\"\\n Testing fixed collection function...\")\n",
    "    fixed_test = collect_wb_indicator_fixed('NY.GDP.PCAP.KD', 'gdp_per_capita_constant', high_quality_countries)\n",
    "    \n",
    "    if fixed_test is not None:\n",
    "        print(f\"\\n FIXED APPROACH WORKS!\")\n",
    "        print(f\"   Total records: {len(fixed_test)}\")\n",
    "        print(f\"   Countries found: {fixed_test['country_code'].nunique()}\")\n",
    "        print(f\"   Year range: {fixed_test['year'].min()}-{fixed_test['year'].max()}\")\n",
    "        \n",
    "        # Show countries found\n",
    "        countries_found = sorted(fixed_test['country_code'].unique())\n",
    "        countries_missing = [c for c in high_quality_countries if c not in countries_found]\n",
    "        \n",
    "        print(f\"\\n COUNTRY COVERAGE:\")\n",
    "        print(f\"   Found: {len(countries_found)}/{len(high_quality_countries)} ({len(countries_found)/len(high_quality_countries):.1%})\")\n",
    "        print(f\"   Countries found: {countries_found}\")\n",
    "        \n",
    "        if countries_missing:\n",
    "            print(f\"   Missing: {countries_missing}\")\n",
    "        \n",
    "        print(f\"\\n SAMPLE DATA:\")\n",
    "        display(fixed_test.head(10))\n",
    "        \n",
    "        # Test data quality\n",
    "        country_coverage = fixed_test.groupby('country_code').size().sort_values(ascending=False)\n",
    "        print(f\"\\n DATA POINTS PER COUNTRY (top 10):\")\n",
    "        print(dict(country_coverage.head(10)))\n",
    "        \n",
    "        collection_working = True\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\n Fixed approach still failed\")\n",
    "        collection_working = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALTERNATIVE: COUNTRY-SPECIFIC COLLECTION\n",
      "==================================================\n",
      "\n",
      " Testing batch collection approach...\n",
      "   Collecting: gdp_per_capita_constant\n",
      "   Processing 10 countries in batches of 5\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR'] → 170 records\n",
      "Batch 2: ['MEX', 'MYS', 'NLD', 'NOR', 'PHL'] → 170 records\n",
      "      Total: 340 records, 10 countries\n",
      "\n",
      " BATCH APPROACH WORKS!\n",
      "   Records: 340\n",
      "   Countries: 10\n",
      "   Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "      <th>year</th>\n",
       "      <th>indicator_code</th>\n",
       "      <th>indicator_name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2023</td>\n",
       "      <td>NY.GDP.PCAP.KD</td>\n",
       "      <td>gdp_per_capita_constant</td>\n",
       "      <td>12933.249734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2022</td>\n",
       "      <td>NY.GDP.PCAP.KD</td>\n",
       "      <td>gdp_per_capita_constant</td>\n",
       "      <td>13182.793395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2021</td>\n",
       "      <td>NY.GDP.PCAP.KD</td>\n",
       "      <td>gdp_per_capita_constant</td>\n",
       "      <td>12549.281170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2020</td>\n",
       "      <td>NY.GDP.PCAP.KD</td>\n",
       "      <td>gdp_per_capita_constant</td>\n",
       "      <td>11393.050596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2019</td>\n",
       "      <td>NY.GDP.PCAP.KD</td>\n",
       "      <td>gdp_per_capita_constant</td>\n",
       "      <td>12706.397811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_code country_name  year  indicator_code           indicator_name  \\\n",
       "0          ARG    Argentina  2023  NY.GDP.PCAP.KD  gdp_per_capita_constant   \n",
       "1          ARG    Argentina  2022  NY.GDP.PCAP.KD  gdp_per_capita_constant   \n",
       "2          ARG    Argentina  2021  NY.GDP.PCAP.KD  gdp_per_capita_constant   \n",
       "3          ARG    Argentina  2020  NY.GDP.PCAP.KD  gdp_per_capita_constant   \n",
       "4          ARG    Argentina  2019  NY.GDP.PCAP.KD  gdp_per_capita_constant   \n",
       "\n",
       "          value  \n",
       "0  12933.249734  \n",
       "1  13182.793395  \n",
       "2  12549.281170  \n",
       "3  11393.050596  \n",
       "4  12706.397811  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ALTERNATIVE: Country- Specific Request\n",
    "# ======================================================\n",
    "\n",
    "print(\"ALTERNATIVE: COUNTRY-SPECIFIC COLLECTION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def collect_wb_by_country_batch(indicator_code: str, indicator_name: str, \n",
    "                               target_countries: List[str], batch_size: int = 10) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Collect World Bank data by requesting specific countries in batches.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"   Collecting: {indicator_name}\")\n",
    "    print(f\"   Processing {len(target_countries)} countries in batches of {batch_size}\")\n",
    "    \n",
    "    all_records = []\n",
    "    \n",
    "    # Process countries in batches\n",
    "    for i in range(0, len(target_countries), batch_size):\n",
    "        batch = target_countries[i:i+batch_size]\n",
    "        batch_str = ';'.join(batch)\n",
    "        \n",
    "        print(f\"Batch {i//batch_size + 1}: {batch}\", end=\"\")\n",
    "        \n",
    "        try:\n",
    "            url = f\"https://api.worldbank.org/v2/country/{batch_str}/indicator/{indicator_code}\"\n",
    "            params = {\n",
    "                'format': 'json',\n",
    "                'date': f'{START_YEAR}:{END_YEAR}',\n",
    "                'per_page': 5000\n",
    "            }\n",
    "            \n",
    "            response = requests.get(url, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            \n",
    "            if isinstance(data, list) and len(data) >= 2:\n",
    "                records_data = data[1]\n",
    "                \n",
    "                if records_data:\n",
    "                    batch_valid = 0\n",
    "                    for item in records_data:\n",
    "                        if not isinstance(item, dict):\n",
    "                            continue\n",
    "                        \n",
    "                        country_code = item.get('countryiso3code')\n",
    "                        country_info = item.get('country', {})\n",
    "                        country_name = country_info.get('value')\n",
    "                        year_str = item.get('date')\n",
    "                        value = item.get('value')\n",
    "                        \n",
    "                        if country_code and year_str and value is not None:\n",
    "                            try:\n",
    "                                year = int(year_str)\n",
    "                                value_float = float(value)\n",
    "                                \n",
    "                                all_records.append({\n",
    "                                    'country_code': country_code,\n",
    "                                    'country_name': country_name,\n",
    "                                    'year': year,\n",
    "                                    'indicator_code': indicator_code,\n",
    "                                    'indicator_name': indicator_name,\n",
    "                                    'value': value_float\n",
    "                                })\n",
    "                                batch_valid += 1\n",
    "                                \n",
    "                            except (ValueError, TypeError):\n",
    "                                continue\n",
    "                    \n",
    "                    print(f\" → {batch_valid} records\")\n",
    "                else:\n",
    "                    print(f\" → no data\")\n",
    "            else:\n",
    "                print(f\" → invalid response\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\" → error: {str(e)[:50]}\")\n",
    "        \n",
    "        # Small delay between batches\n",
    "        time.sleep(1)\n",
    "    \n",
    "    if all_records:\n",
    "        df = pd.DataFrame(all_records)\n",
    "        countries_found = df['country_code'].nunique()\n",
    "        print(f\"      Total: {len(all_records)} records, {countries_found} countries\")\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"      No records collected\")\n",
    "        return None\n",
    "\n",
    "# Test the batch approach\n",
    "if success_base:\n",
    "    print(\"\\n Testing batch collection approach...\")\n",
    "    batch_test = collect_wb_by_country_batch('NY.GDP.PCAP.KD', 'gdp_per_capita_constant', \n",
    "                                           high_quality_countries[:10], batch_size=5)  # Test with first 10 countries\n",
    "    \n",
    "    if batch_test is not None:\n",
    "        print(f\"\\n BATCH APPROACH WORKS!\")\n",
    "        print(f\"   Records: {len(batch_test)}\")\n",
    "        print(f\"   Countries: {batch_test['country_code'].nunique()}\")\n",
    "        print(f\"   Sample data:\")\n",
    "        display(batch_test.head())\n",
    "        \n",
    "        batch_working = True\n",
    "    else:\n",
    "        print(f\"\\n Batch approach failed\")\n",
    "        batch_working = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL WORLD BANK DATA COLLECTION\n",
      "=============================================\n",
      "Starting full World Bank collection...\n",
      "Collecting 26 indicators across 7 categories\n",
      "Target: 38 countries, 1990-2023\n",
      "Using batch size: 8 countries per request\n",
      "\n",
      "CATEGORY: Core Economic\n",
      "--------------------------------------------------\n",
      "   [ 1/26] gdp_per_capita_constant\n",
      "   Collecting: gdp_per_capita_constant\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 272 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 272 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 272 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 272 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 204 records\n",
      "      Total: 1292 records, 38 countries\n",
      "Success: 1292 records, 38 countries, quality: 1.000\n",
      "   [ 2/26] gdp_growth_annual\n",
      "   Collecting: gdp_growth_annual\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 272 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 271 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 272 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 271 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 204 records\n",
      "      Total: 1290 records, 38 countries\n",
      "Success: 1290 records, 38 countries, quality: 1.000\n",
      "   [ 3/26] gdp_per_capita_growth\n",
      "   Collecting: gdp_per_capita_growth\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 272 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 271 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 272 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 271 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 204 records\n",
      "      Total: 1290 records, 38 countries\n",
      "Success: 1290 records, 38 countries, quality: 1.000\n",
      "   [ 4/26] gdp_ppp_constant\n",
      "   Collecting: gdp_ppp_constant\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 272 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 272 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 272 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 272 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 204 records\n",
      "      Total: 1292 records, 38 countries\n",
      "Success: 1292 records, 38 countries, quality: 1.000\n",
      "Category result: 4/4 (100.0% success)\n",
      "\n",
      "CATEGORY: Investment & Savings\n",
      "--------------------------------------------------\n",
      "   [ 5/26] gross_investment_gdp\n",
      "   Collecting: gross_investment_gdp\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 272 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 267 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 271 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 272 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 204 records\n",
      "      Total: 1286 records, 38 countries\n",
      "Success: 1286 records, 38 countries, quality: 1.000\n",
      "   [ 6/26] gross_savings_gdp\n",
      "   Collecting: gross_savings_gdp\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 256 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 263 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 229 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 269 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 204 records\n",
      "      Total: 1221 records, 38 countries\n",
      "Success: 1221 records, 38 countries, quality: 1.000\n",
      "   [ 7/26] private_investment_gdp\n",
      "   Collecting: private_investment_gdp\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 102 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 124 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 30 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 31 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 34 records\n",
      "      Total: 321 records, 12 countries\n",
      "Success: 321 records, 12 countries, quality: 0.489\n",
      "   [ 8/26] fdi_net_inflows_gdp\n",
      "   Collecting: fdi_net_inflows_gdp\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 272 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 270 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 272 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 269 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 204 records\n",
      "      Total: 1287 records, 38 countries\n",
      "Success: 1287 records, 38 countries, quality: 1.000\n",
      "Category result: 4/4 (100.0% success)\n",
      "\n",
      "CATEGORY: Trade & Openness\n",
      "--------------------------------------------------\n",
      "   [ 9/26] trade_gdp\n",
      "   Collecting: trade_gdp\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 272 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 267 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 271 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 272 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 204 records\n",
      "      Total: 1286 records, 38 countries\n",
      "Success: 1286 records, 38 countries, quality: 1.000\n",
      "   [10/26] exports_gdp\n",
      "   Collecting: exports_gdp\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 272 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 267 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 271 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 272 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 204 records\n",
      "      Total: 1286 records, 38 countries\n",
      "Success: 1286 records, 38 countries, quality: 1.000\n",
      "   [11/26] imports_gdp\n",
      "   Collecting: imports_gdp\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 272 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 267 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 271 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 272 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 204 records\n",
      "      Total: 1286 records, 38 countries\n",
      "Success: 1286 records, 38 countries, quality: 1.000\n",
      "   [12/26] tariff_rate_applied_weighted\n",
      "   Collecting: tariff_rate_applied_weighted\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 217 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 207 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 208 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 231 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 145 records\n",
      "      Total: 1008 records, 38 countries\n",
      "Success: 1008 records, 38 countries, quality: 0.965\n",
      "Category result: 4/4 (100.0% success)\n",
      "\n",
      "CATEGORY: Financial Development\n",
      "--------------------------------------------------\n",
      "   [13/26] domestic_credit_private_gdp\n",
      "   Collecting: domestic_credit_private_gdp\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 104 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 51 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 65 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 54 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 33 records\n",
      "      Total: 307 records, 15 countries\n",
      "Success: 307 records, 15 countries, quality: 0.481\n",
      "   [14/26] bank_capital_assets_ratio\n",
      "   Collecting: bank_capital_assets_ratio\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 113 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 106 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 133 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 125 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 86 records\n",
      "      Total: 563 records, 37 countries\n",
      "Success: 563 records, 37 countries, quality: 0.834\n",
      "   [15/26] market_cap_gdp\n",
      "   Collecting: market_cap_gdp\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 249 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 201 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 219 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 213 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 152 records\n",
      "      Total: 1034 records, 38 countries\n",
      "Success: 1034 records, 38 countries, quality: 0.972\n",
      "   [16/26] real_interest_rate\n",
      "   Collecting: real_interest_rate\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 202 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 145 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 133 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 199 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 59 records\n",
      "      Total: 738 records, 27 countries\n",
      "Success: 738 records, 27 countries, quality: 0.771\n",
      "Category result: 4/4 (100.0% success)\n",
      "\n",
      "CATEGORY: Government & Fiscal\n",
      "--------------------------------------------------\n",
      "   [17/26] government_debt_gdp\n",
      "   Collecting: government_debt_gdp\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 125 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 154 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 212 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 106 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 122 records\n",
      "      Total: 719 records, 36 countries\n",
      "Success: 719 records, 36 countries, quality: 0.863\n",
      "   [18/26] tax_revenue_gdp\n",
      "   Collecting: tax_revenue_gdp\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 215 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 257 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 233 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 218 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 194 records\n",
      "      Total: 1117 records, 38 countries\n",
      "Success: 1117 records, 38 countries, quality: 0.994\n",
      "   [19/26] government_expenditure_gdp\n",
      "   Collecting: government_expenditure_gdp\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 232 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 254 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 232 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 199 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 194 records\n",
      "      Total: 1111 records, 37 countries\n",
      "Success: 1111 records, 37 countries, quality: 0.982\n",
      "Category result: 3/3 (100.0% success)\n",
      "\n",
      "CATEGORY: Labor & Social\n",
      "--------------------------------------------------\n",
      "   [20/26] unemployment_total\n",
      "   Collecting: unemployment_total\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 264 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 264 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 264 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 264 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 198 records\n",
      "      Total: 1254 records, 38 countries\n",
      "Success: 1254 records, 38 countries, quality: 1.000\n",
      "   [21/26] tertiary_education_enrollment\n",
      "   Collecting: tertiary_education_enrollment\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 220 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 223 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 235 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 225 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 182 records\n",
      "      Total: 1085 records, 38 countries\n",
      "Success: 1085 records, 38 countries, quality: 0.986\n",
      "   [22/26] population_growth\n",
      "   Collecting: population_growth\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 271 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 272 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 272 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 272 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 204 records\n",
      "      Total: 1291 records, 38 countries\n",
      "Success: 1291 records, 38 countries, quality: 1.000\n",
      "   [23/26] urban_population_pct\n",
      "   Collecting: urban_population_pct\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 272 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 272 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 272 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 272 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 204 records\n",
      "      Total: 1292 records, 38 countries\n",
      "Success: 1292 records, 38 countries, quality: 1.000\n",
      "Category result: 4/4 (100.0% success)\n",
      "\n",
      "CATEGORY: Innovation & Tech\n",
      "--------------------------------------------------\n",
      "   [24/26] research_development_gdp\n",
      "   Collecting: research_development_gdp\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 192 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 175 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 196 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 175 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 156 records\n",
      "      Total: 894 records, 38 countries\n",
      "Success: 894 records, 38 countries, quality: 0.935\n",
      "   [25/26] patent_applications_residents\n",
      "   Collecting: patent_applications_residents\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 244 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 254 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 230 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 252 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 192 records\n",
      "      Total: 1172 records, 38 countries\n",
      "Success: 1172 records, 38 countries, quality: 1.000\n",
      "   [26/26] internet_users_pct\n",
      "   Collecting: internet_users_pct\n",
      "   Processing 38 countries in batches of 8\n",
      "Batch 1: ['ARG', 'NZL', 'ITA', 'JPN', 'KOR', 'MEX', 'MYS', 'NLD'] → 269 records\n",
      "Batch 2: ['NOR', 'PHL', 'AUS', 'POL', 'PRT', 'RUS', 'SWE', 'THA'] → 265 records\n",
      "Batch 3: ['TUR', 'USA', 'IRL', 'IND', 'IDN', 'HUN', 'AUT', 'BEL'] → 264 records\n",
      "Batch 4: ['BRA', 'CAN', 'CHE', 'CHL', 'CHN', 'COL', 'CZE', 'DEU'] → 264 records\n",
      "Batch 5: ['DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'ZAF'] → 204 records\n",
      "      Total: 1266 records, 38 countries\n",
      "Success: 1266 records, 38 countries, quality: 1.000\n",
      "Category result: 3/3 (100.0% success)\n",
      "\n",
      " COLLECTION COMPLETE!\n",
      "==============================\n",
      "Total time: 2.7 minutes\n",
      "Successful indicators: 26/26\n",
      "Overall success rate: 100.0%\n",
      "Total records collected: 27,988\n",
      "\n",
      "Collection successful!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# FULL WORLD BANK COLLECTION - USING BATCH APPROACH\n",
    "#====================================================\n",
    "\n",
    "print(\"FULL WORLD BANK DATA COLLECTION\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "def collect_all_wb_indicators_batch(target_countries: List[str], \n",
    "                                  indicators_dict: Dict[str, str],\n",
    "                                  batch_size: int = 8) -> Dict:\n",
    "    \"\"\"\n",
    "    Collect all World Bank indicators using efficient batch approach.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    target_countries : List[str]\n",
    "        List of country codes to collect\n",
    "    indicators_dict : Dict[str, str] \n",
    "        Dictionary of indicator_code: indicator_name\n",
    "    batch_size : int\n",
    "        Number of countries per batch\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Dict : Collection results and summary\n",
    "    \"\"\"\n",
    "    \n",
    "    # Organize indicators by category for better tracking\n",
    "    indicator_categories = {\n",
    "        'Core Economic': {\n",
    "            'NY.GDP.PCAP.KD': 'gdp_per_capita_constant',\n",
    "            'NY.GDP.MKTP.KD.ZG': 'gdp_growth_annual', \n",
    "            'NY.GDP.PCAP.KD.ZG': 'gdp_per_capita_growth',\n",
    "            'NY.GDP.MKTP.PP.KD': 'gdp_ppp_constant'\n",
    "        },\n",
    "        'Investment & Savings': {\n",
    "            'NE.GDI.TOTL.ZS': 'gross_investment_gdp',\n",
    "            'NY.GNS.ICTR.ZS': 'gross_savings_gdp',\n",
    "            'NE.GDI.FPRV.ZS': 'private_investment_gdp',\n",
    "            'BX.KLT.DINV.WD.GD.ZS': 'fdi_net_inflows_gdp'\n",
    "        },\n",
    "        'Trade & Openness': {\n",
    "            'NE.TRD.GNFS.ZS': 'trade_gdp',\n",
    "            'NE.EXP.GNFS.ZS': 'exports_gdp',\n",
    "            'NE.IMP.GNFS.ZS': 'imports_gdp',\n",
    "            'TM.TAX.MRCH.WM.AR.ZS': 'tariff_rate_applied_weighted'\n",
    "        },\n",
    "        'Financial Development': {\n",
    "            'FS.AST.DOMS.GD.ZS': 'domestic_credit_private_gdp',\n",
    "            'FB.BNK.CAPA.ZS': 'bank_capital_assets_ratio',\n",
    "            'CM.MKT.LCAP.GD.ZS': 'market_cap_gdp',\n",
    "            'FR.INR.RINR': 'real_interest_rate'\n",
    "        },\n",
    "        'Government & Fiscal': {\n",
    "            'GC.DOD.TOTL.GD.ZS': 'government_debt_gdp',\n",
    "            'GC.TAX.TOTL.GD.ZS': 'tax_revenue_gdp',\n",
    "            'GC.XPN.TOTL.GD.ZS': 'government_expenditure_gdp'\n",
    "        },\n",
    "        'Labor & Social': {\n",
    "            'SL.UEM.TOTL.ZS': 'unemployment_total',\n",
    "            'SE.TER.ENRR': 'tertiary_education_enrollment',\n",
    "            'SP.POP.GROW': 'population_growth',\n",
    "            'SP.URB.TOTL.IN.ZS': 'urban_population_pct'\n",
    "        },\n",
    "        'Innovation & Tech': {\n",
    "            'GB.XPD.RSDV.GD.ZS': 'research_development_gdp',\n",
    "            'IP.PAT.RESD': 'patent_applications_residents',\n",
    "            'IT.NET.USER.ZS': 'internet_users_pct'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Collection tracking\n",
    "    all_data = []\n",
    "    collection_summary = []\n",
    "    category_results = {}\n",
    "    \n",
    "    total_indicators = sum(len(cat_indicators) for cat_indicators in indicator_categories.values())\n",
    "    collected_count = 0\n",
    "    \n",
    "    print(f\"Collecting {total_indicators} indicators across {len(indicator_categories)} categories\")\n",
    "    print(f\"Target: {len(target_countries)} countries, {START_YEAR}-{END_YEAR}\")\n",
    "    print(f\"Using batch size: {batch_size} countries per request\")\n",
    "    \n",
    "    collection_start = time.time()\n",
    "    \n",
    "    # Collect by category\n",
    "    for category_name, category_indicators in indicator_categories.items():\n",
    "        print(f\"\\nCATEGORY: {category_name}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        category_data = []\n",
    "        category_success = 0\n",
    "        \n",
    "        for indicator_code, indicator_name in category_indicators.items():\n",
    "            collected_count += 1\n",
    "            print(f\"   [{collected_count:2d}/{total_indicators}] {indicator_name}\")\n",
    "            \n",
    "            # Collect this indicator\n",
    "            indicator_df = collect_wb_by_country_batch(\n",
    "                indicator_code, indicator_name, target_countries, batch_size\n",
    "            )\n",
    "            \n",
    "            if indicator_df is not None and len(indicator_df) > 0:\n",
    "                # Quality assessment\n",
    "                countries_covered = indicator_df['country_code'].nunique()\n",
    "                coverage_rate = countries_covered / len(target_countries)\n",
    "                avg_data_points = len(indicator_df) / countries_covered if countries_covered > 0 else 0\n",
    "                \n",
    "                # Quality score based on coverage and data density\n",
    "                quality_score = coverage_rate * 0.7 + min(avg_data_points / 30, 1.0) * 0.3\n",
    "                \n",
    "                if quality_score > 0.4:  # Accept if reasonable quality\n",
    "                    all_data.append(indicator_df)\n",
    "                    category_data.append(indicator_df)\n",
    "                    category_success += 1\n",
    "                    \n",
    "                    print(f\"Success: {len(indicator_df)} records, {countries_covered} countries, \"\n",
    "                          f\"quality: {quality_score:.3f}\")\n",
    "                    \n",
    "                    collection_summary.append({\n",
    "                        'category': category_name,\n",
    "                        'indicator_code': indicator_code,\n",
    "                        'indicator_name': indicator_name,\n",
    "                        'status': 'success',\n",
    "                        'records': len(indicator_df),\n",
    "                        'countries': countries_covered,\n",
    "                        'coverage_rate': coverage_rate,\n",
    "                        'quality_score': quality_score\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"      ⚠️ Low quality: {quality_score:.3f}, skipping\")\n",
    "                    collection_summary.append({\n",
    "                        'category': category_name,\n",
    "                        'indicator_code': indicator_code,\n",
    "                        'indicator_name': indicator_name,\n",
    "                        'status': 'low_quality',\n",
    "                        'records': len(indicator_df) if indicator_df is not None else 0,\n",
    "                        'countries': countries_covered,\n",
    "                        'coverage_rate': coverage_rate,\n",
    "                        'quality_score': quality_score\n",
    "                    })\n",
    "            else:\n",
    "                print(f\"Failed: No data collected\")\n",
    "                collection_summary.append({\n",
    "                    'category': category_name,\n",
    "                    'indicator_code': indicator_code,\n",
    "                    'indicator_name': indicator_name,\n",
    "                    'status': 'failed',\n",
    "                    'records': 0,\n",
    "                    'countries': 0,\n",
    "                    'coverage_rate': 0,\n",
    "                    'quality_score': 0\n",
    "                })\n",
    "        \n",
    "        # Category summary\n",
    "        category_results[category_name] = {\n",
    "            'attempted': len(category_indicators),\n",
    "            'successful': category_success,\n",
    "            'success_rate': category_success / len(category_indicators)\n",
    "        }\n",
    "        \n",
    "        print(f\"Category result: {category_success}/{len(category_indicators)} \"\n",
    "              f\"({category_success/len(category_indicators):.1%} success)\")\n",
    "    \n",
    "    collection_time = time.time() - collection_start\n",
    "    \n",
    "    # Overall summary\n",
    "    successful_collections = [item for item in collection_summary if item['status'] == 'success']\n",
    "    \n",
    "    print(f\"\\n COLLECTION COMPLETE!\")\n",
    "    print(\"=\" * 30)\n",
    "    print(f\"Total time: {collection_time/60:.1f} minutes\")\n",
    "    print(f\"Successful indicators: {len(successful_collections)}/{total_indicators}\")\n",
    "    print(f\"Overall success rate: {len(successful_collections)/total_indicators:.1%}\")\n",
    "    print(f\"Total records collected: {sum(len(df) for df in all_data):,}\")\n",
    "    \n",
    "    return {\n",
    "        'data_frames': all_data,\n",
    "        'summary': collection_summary,\n",
    "        'category_results': category_results,\n",
    "        'collection_time': collection_time,\n",
    "        'successful_count': len(successful_collections)\n",
    "    }\n",
    "\n",
    "# Run the full collection\n",
    "if success_base:\n",
    "    print(\"Starting full World Bank collection...\")\n",
    "    wb_results = collect_all_wb_indicators_batch(\n",
    "        high_quality_countries, \n",
    "        WORLD_BANK_INDICATORS,\n",
    "        batch_size=8  # Optimal batch size\n",
    "    )\n",
    "    \n",
    "    if wb_results['successful_count'] > 0:\n",
    "        print(f\"\\nCollection successful!\")\n",
    "        wb_collection_success = True\n",
    "    else:\n",
    "        print(f\"\\nCollection failed!\")\n",
    "        wb_collection_success = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PROCESSING WORLD BANK RESULTS\n",
      "========================================\n",
      "   Combining all indicator datasets...\n",
      "   Combined dataset: (27988, 6)\n",
      "   Indicators: 26\n",
      "   Countries: 38\n",
      "   Years: 1990-2023\n",
      "   Creating wide format...\n",
      "Wide format: (1292, 29)\n",
      "   Integrating with Maddison data...\n",
      "Final integrated dataset: (1292, 32)\n",
      "\n",
      " SAVING RESULTS:\n",
      "   World Bank data: data/worldbank_batch_collection.csv\n",
      "   Final dataset: data/final_integrated_dataset.csv\n",
      "   Collection summary: data/worldbank_collection_summary.csv\n",
      "\n",
      "FINAL RESULTS SUMMARY:\n",
      "==============================\n",
      "Successful indicators: 26\n",
      "Countries in final dataset: 38\n",
      "Final dataset shape: (1292, 32)\n",
      "Time period: 1990-2023\n",
      "\n",
      " SUCCESS BY CATEGORY:\n",
      "   Core Economic: 4/4 (100.0%)\n",
      "   Investment & Savings: 4/4 (100.0%)\n",
      "   Trade & Openness: 4/4 (100.0%)\n",
      "   Financial Development: 4/4 (100.0%)\n",
      "   Government & Fiscal: 3/3 (100.0%)\n",
      "   Labor & Social: 4/4 (100.0%)\n",
      "   Innovation & Tech: 3/3 (100.0%)\n",
      "\n",
      " DATA QUALITY:\n",
      "   Overall data coverage: 84.8%\n",
      "   Maddison + WB indicators: 29\n",
      "\n",
      " READY FOR PHASE 2: FEATURE ENGINEERING!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Process and Save World Bank Results \n",
    "# ======================================================\n",
    "\n",
    "if 'wb_results' in locals() and wb_collection_success:\n",
    "    print(\" PROCESSING WORLD BANK RESULTS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Combine all successful data frames\n",
    "    print(\"   Combining all indicator datasets...\")\n",
    "    wb_combined = pd.concat(wb_results['data_frames'], ignore_index=True)\n",
    "    \n",
    "    print(f\"   Combined dataset: {wb_combined.shape}\")\n",
    "    print(f\"   Indicators: {wb_combined['indicator_name'].nunique()}\")\n",
    "    print(f\"   Countries: {wb_combined['country_code'].nunique()}\")\n",
    "    print(f\"   Years: {wb_combined['year'].min()}-{wb_combined['year'].max()}\")\n",
    "    \n",
    "    # Create wide format\n",
    "    print(\"   Creating wide format...\")\n",
    "    wb_wide = wb_combined.pivot_table(\n",
    "        index=['country_code', 'country_name', 'year'],\n",
    "        columns='indicator_name',\n",
    "        values='value',\n",
    "        aggfunc='first'\n",
    "    ).reset_index()\n",
    "    wb_wide.columns.name = None\n",
    "    \n",
    "    print(f\"Wide format: {wb_wide.shape}\")\n",
    "    \n",
    "    # Integration with Maddison\n",
    "    print(\"   Integrating with Maddison data...\")\n",
    "    maddison_data = pd.read_csv('data/maddison_focused_test.csv')\n",
    "    \n",
    "    integrated_final = maddison_data.merge(\n",
    "        wb_wide,\n",
    "        on=['country_code', 'year'],\n",
    "        how='outer',\n",
    "        suffixes=('_maddison', '_wb')\n",
    "    )\n",
    "    \n",
    "    # Handle duplicate country names\n",
    "    if 'country_name_maddison' in integrated_final.columns:\n",
    "        integrated_final['country_name'] = integrated_final['country_name_maddison'].fillna(\n",
    "            integrated_final['country_name_wb']\n",
    "        )\n",
    "        integrated_final = integrated_final.drop(['country_name_maddison', 'country_name_wb'], axis=1)\n",
    "    \n",
    "    print(f\"Final integrated dataset: {integrated_final.shape}\")\n",
    "    \n",
    "    # Save all results\n",
    "    print(f\"\\n SAVING RESULTS:\")\n",
    "    wb_wide.to_csv('data/worldbank_batch_collection.csv', index=False)\n",
    "    integrated_final.to_csv('data/final_integrated_dataset.csv', index=False) #This is our main dataset for analysis with WB Data\n",
    "    \n",
    "    # Save summary\n",
    "    summary_df = pd.DataFrame(wb_results['summary'])\n",
    "    summary_df.to_csv('data/worldbank_collection_summary.csv', index=False)\n",
    "    \n",
    "    print(f\"   World Bank data: data/worldbank_batch_collection.csv\")\n",
    "    print(f\"   Final dataset: data/final_integrated_dataset.csv\") \n",
    "    print(f\"   Collection summary: data/worldbank_collection_summary.csv\")\n",
    "    \n",
    "    # Quality analysis\n",
    "    successful_indicators = summary_df[summary_df['status'] == 'success']\n",
    "    \n",
    "    print(f\"\\nFINAL RESULTS SUMMARY:\")\n",
    "    print(\"=\" * 30)\n",
    "    print(f\"Successful indicators: {len(successful_indicators)}\")\n",
    "    print(f\"Countries in final dataset: {integrated_final['country_code'].nunique()}\")\n",
    "    print(f\"Final dataset shape: {integrated_final.shape}\")\n",
    "    print(f\"Time period: {integrated_final['year'].min()}-{integrated_final['year'].max()}\")\n",
    "    \n",
    "    # Category performance\n",
    "    print(f\"\\n SUCCESS BY CATEGORY:\")\n",
    "    for category, results in wb_results['category_results'].items():\n",
    "        print(f\"   {category}: {results['successful']}/{results['attempted']} \"\n",
    "              f\"({results['success_rate']:.1%})\")\n",
    "    \n",
    "    # Coverage analysis\n",
    "    numeric_cols = integrated_final.select_dtypes(include=[np.number]).columns\n",
    "    overall_coverage = integrated_final[numeric_cols].notna().mean().mean()\n",
    "    \n",
    "    print(f\"\\n DATA QUALITY:\")\n",
    "    print(f\"   Overall data coverage: {overall_coverage:.1%}\")\n",
    "    print(f\"   Maddison + WB indicators: {len(numeric_cols)}\")\n",
    "    \n",
    "    print(f\"\\n READY FOR PHASE 2: FEATURE ENGINEERING!\")\n",
    "    \n",
    "    final_success = True\n",
    "else:\n",
    "    print(\" Cannot process results - collection failed\")\n",
    "    final_success = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
